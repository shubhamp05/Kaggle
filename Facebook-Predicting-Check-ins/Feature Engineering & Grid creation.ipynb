{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_author_ = https://www.kaggle.com\\shubhamp05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import gc\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Function to prepare data\n",
    "\n",
    "def remove_infrequent_place_id(df):\n",
    "    places,count = np.unique(df.place_id.values,return_counts=True)\n",
    "    places = places[count>=10]\n",
    "    df = df.loc[df.place_id.isin(places)]\n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## This is a way to calculate MAP@k with only one truth values\n",
    "def mapkprecision(truth,prediction):\n",
    "    z = (prediction == truth[:,None]).astype(np.float32)\n",
    "    w = 1./(np.arange(prediction.shape[1],dtype = np.float32) +1.)\n",
    "    z = z * w[None,:]\n",
    "    return(np.mean(np.sum(z,axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    types = {'row_id': np.dtype(np.int32),\n",
    "         'x': np.dtype(float),\n",
    "         'y' : np.dtype(float),\n",
    "         'accuracy': np.dtype(np.int16),\n",
    "         'place_id': np.int64,\n",
    "         'time': np.dtype(np.int32)}\n",
    "    train = pd.read_csv('train.csv/train.csv',dtype=types)\n",
    "    test = pd.read_csv('test.csv/test.csv',dtype=types)\n",
    "    return(train,test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Calculation distance\n",
    "def calc_distance(distance):\n",
    "    return(distance ** -2.225)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def process_cell(train,test,fw,th,n_neighbors):\n",
    "    # remove infrequent places\n",
    "    train = remove_infrequent_place_id(train)\n",
    "    \n",
    "    ## storing row_ids of test to generate submission\n",
    "    row_id = test['row_id'].values\n",
    "    test.drop('row_id',axis=1,inplace=True)\n",
    "    \n",
    "    ## preparing data\n",
    "    le = LabelEncoder()\n",
    "    y = le.fit_transform(train.place_id.values)\n",
    "    train.drop('place_id',axis=1,inplace=True)\n",
    "    \n",
    "    ## Applying the classifier\n",
    "    knn = KNeighborsClassifier(n_neighbors=n_neighbors,weights=calc_distance,n_jobs=2,leaf_size=15,p=1)\n",
    "    \n",
    "    knn.fit(train,y)\n",
    "    \n",
    "    preds = knn.predict_proba(test)\n",
    "    preds = le.inverse_transform(np.argsort(preds,axis=1)[:,::-1][:,0:3])\n",
    "    return(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Create time_dict, to not to create in every iteration\n",
    "def create_time_dict(t_cuts,time_factor,time_expansion):\n",
    "    t_slice = 24/t_cuts\n",
    "    time_dict = dict()\n",
    "    \n",
    "    for t in range(t_cuts):\n",
    "        t_min = 2*np.pi*(t*t_slice*12 / 288)\n",
    "        t_max = 2*np.pi*(((t+1)*t_slice*12 -1)/288)\n",
    "        sin_t_start = np.sin(t_min) * time_factor\n",
    "        sin_t_stop = np.sin(t_max) * time_factor\n",
    "        cos_t_start = np.cos(t_min) * time_factor\n",
    "        cos_t_stop = np.cos(t_max) * time_factor\n",
    "        \n",
    "        sin_t_min = min(sin_t_start,sin_t_stop)\n",
    "        sin_t_max = max(sin_t_start,sin_t_stop)\n",
    "        cos_t_min = min(cos_t_start,cos_t_stop)\n",
    "        cos_t_max = max(cos_t_start,cos_t_stop)\\\n",
    "        \n",
    "        time_dict[t] = [sin_t_min,sin_t_max,cos_t_min,cos_t_max]\n",
    "        \n",
    "        t_min = 2 * np.pi * ((t * t_slice - time_expansion) * 12 / 288)\n",
    "        t_max = 2 * np.pi * ((((t + 1) * t_slice + time_expansion)* 12 - 1) / 288)\n",
    "        sin_t_start = np.round(np.sin(t_min)+1, 4) * time_factor\n",
    "        sin_t_stop = np.round(np.sin(t_max)+1, 4) * time_factor\n",
    "        cos_t_start = np.round(np.cos(t_min)+1, 4) * time_factor\n",
    "        cos_t_stop = np.round(np.cos(t_max)+1, 4) * time_factor\n",
    "        sin_t_min = min((sin_t_start, sin_t_stop, sin_t_min))\n",
    "        sin_t_max = max((sin_t_start, sin_t_stop, sin_t_max))\n",
    "        cos_t_min = min((cos_t_start, cos_t_stop, cos_t_min))\n",
    "        cos_t_max = max((cos_t_start, cos_t_stop, cos_t_max))\n",
    "        time_dict[t] += [sin_t_min, sin_t_max, cos_t_min, cos_t_max]\n",
    "        \n",
    "        return(time_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Feature Engineering\n",
    "## In this function I am going to utilize periodic property of Sine & Cosine and use \"time\" feature to extract more features\n",
    "\n",
    "def feature_engineering(df):\n",
    "    minute = 2*np.pi*((df.time//5)%288)/288\n",
    "    \n",
    "    ## sine feature of minute\n",
    "    df['minute_sine'] = np.sin(minute)\n",
    "    \n",
    "    ## Cosine feature of minute\n",
    "    df['minute_cosine'] = np.cos(minute)\n",
    "    \n",
    "    ## Weekday feature\n",
    "    weekday = 2*np.pi*((df.time/(60*24))%7)\n",
    "    \n",
    "    ## sine of weekday\n",
    "    df['weekday_sine'] = np.sin(weekday)\n",
    "    \n",
    "    ## Cosine of weekday\n",
    "    df['weekday_cosine'] = np.cos(weekday)\n",
    "    \n",
    "    ## Day feature\n",
    "    day = 2*np.pi*((df.time/(60*24))%365)\n",
    "    \n",
    "    ## Sine of day\n",
    "    df['day_sine'] = np.sin(day)\n",
    "    \n",
    "    ## Cosine of day\n",
    "    df['day_cosine'] = np.cos(day)\n",
    "    \n",
    "    ## Year feature\n",
    "    year = 2*np.pi*((df.time/(60*24*365)))\n",
    "    \n",
    "    df['year_sine'] = np.sin(year)\n",
    "    df['year_cosine'] = np.cos(year)\n",
    "    \n",
    "    ## Month Feature\n",
    "    month = 2*np.pi*((df.time/(60*24*30))%12)\n",
    "    \n",
    "    df['month_sine'] = np.sin(month)\n",
    "    df['month_cosine'] = np.cos(month)\n",
    "    \n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## To Process grids\n",
    "def  grid_process(train,test,x_cuts,y_cuts,t_cuts,x_border_expansion,y_border_expansion,time_epansion,fw,th,n_neighbors):\n",
    "    preds_list = []\n",
    "    \n",
    "    ## Calculating x,y & time slice in train dataset\n",
    "    x_slice = train['x'].max()/x_cuts\n",
    "    y_slice = train['y'].max()/y_cuts\n",
    "    time_max = train['minute_sine'].max()\n",
    "    time_factor = time_max / 2\n",
    "    \n",
    "    ## Creating time_dict\n",
    "    time_dict = create_time_dict(t_cuts,time_factor,time_expansion)\n",
    "    \n",
    "    ## Looping over x-axis cuts\n",
    "    \n",
    "    for i in range(x_cuts):\n",
    "        x_min = x_slice * i\n",
    "        x_max = x_slice * (i+1)\n",
    "        x_max += int((i+1) == x_cuts)\n",
    "        \n",
    "        mask = (test['x'] >= x_min)& (test['x'] < x_max)\n",
    "        \n",
    "        df_test = test.loc[mask]\n",
    "        x_min -= x_border_expansion\n",
    "        x_max += x_border_expansion\n",
    "        \n",
    "        mask = (train['x']>=x_min)& (train['x']<x_max)\n",
    "        df_train = train.loc[mask]\n",
    "        \n",
    "        for j in range(y_cuts):\n",
    "            y_min = y_slice * j\n",
    "            y_max = y_slice * (j+1)\n",
    "            \n",
    "            y_max += int((j+1) == y_cuts)\n",
    "            \n",
    "            mask = (test['y'] >= y_min) & (test['y']>y_max)\n",
    "            \n",
    "            df_test = df_test[mask]\n",
    "            \n",
    "            y_min -= y_border_expansion\n",
    "            y_max += y_border_expansion\n",
    "            \n",
    "            mask = (train['y']>=x_min)& (train['y']<x_max)\n",
    "            df_train = train.loc[mask]\n",
    "        \n",
    "            for t in range(t_cuts):\n",
    "                #print(df_row_test.shape, df_row_train.shape)\n",
    "                t_lim = time_dict[t]\n",
    "                mask = df_test['minute_sine'].between(t_lim[0], t_lim[1])\n",
    "                mask = mask & df_test['minute_cosine'].between(t_lim[2], t_lim[3])\n",
    "                df_cell_test = df_test[mask].copy()\n",
    "                mask = df_train['minute_sine'].between(t_lim[4], t_lim[5])\n",
    "                mask = mask & df_train['minute_cosine'].between(t_lim[6], t_lim[7])\n",
    "                df_cell_train = df_train[mask].copy()\n",
    "                cell_pred = process_cell(df_cell_train.copy(), \n",
    "                                             df_cell_test.copy(), \n",
    "                                             fw, th, n_neighbors)\n",
    "                preds_list.append(cell_pred)\n",
    "        elapsed = (time.time() - row_start_time)\n",
    "        print('Row', i, 'completed in:', timedelta(seconds=elapsed))\n",
    "    preds = np.vstack(preds_list)\n",
    "    return(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def validation_split(df,validation_start_day):\n",
    "    day = df['time']//1440\n",
    "    df_val = df[day>=validation_start_day]\n",
    "    df = df[day<validation_start_day]\n",
    "    return(df,df_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def apply_weights(df,weights):\n",
    "    df['accuracy'] *= weights[0]\n",
    "    df['day_sine'] *= weights[1]\n",
    "    df['day_cosine'] *= weights[1]\n",
    "    df['minute_sine'] *= weights[2]\n",
    "    df['minute_cosine'] *= weights[2]\n",
    "    df['weekday_sine'] *= weights[3]\n",
    "    df['weekday_cosine'] *= weights[3]\n",
    "    df.x *= weights[4]\n",
    "    df.y *= weights[5]\n",
    "    df['year_sine'] *= weights[6]\n",
    "    df['year_cosine'] *= weights[6]\n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def prepare_data(validation_start_day,fw):\n",
    "    \n",
    "    ## Loading data from input location\n",
    "    train = pd.read_csv('train.csv/train.csv')\n",
    "    test = pd.read_csv('test.csv/test.csv')\n",
    "    \n",
    "    print(\"the length of train before validation_split: \",len(train))\n",
    "    \n",
    "    ## Create Validation data from validation_split function\n",
    "    ## validation is done on the time axis to remain aligned with kaggle private leaderboard\n",
    "    \n",
    "    train,validation = validation_split(train,validation_start_day)\n",
    "    truth_val = validation.place_id.values\n",
    "    validation.drop('place_id',axis=1,inplace=True)\n",
    "    \n",
    "    print(\"the length of train after validation_split: \",len(train))\n",
    "    ## Some feature Engineering on Train\n",
    "    \n",
    "    ## Drop 'row_id' as row_id is just an enumerate field\n",
    "    train.drop('row_id',axis = 1,inplace = True)\n",
    "    \n",
    "    print(\"length of train:\",len(train))\n",
    "    ## Drop infrequent Place_id's from train\n",
    "    train = remove_infrequent_place_id(train)\n",
    "    \n",
    "    print(train.columns)\n",
    "    \n",
    "    ## Add new features derived\n",
    "    train = feature_engineering(train)\n",
    "    \n",
    "    print(\"the length of train: \",len(train))\n",
    "    \n",
    "    train = apply_weights(train,fw)\n",
    "    print(\"the length of train after apply weights: \",len(train))\n",
    "    \n",
    "    if validation_start_day == 0:\n",
    "        test = feature_engineering(test)\n",
    "        test = apply_weights(test,fw)\n",
    "    \n",
    "    return(train,test,truth_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_submission(preds):    \n",
    "    print('Writing submission file')\n",
    "    print('Pred shape:', preds.shape)\n",
    "    with open('KNN_submission.csv', \"w\") as out:\n",
    "        out.write(\"row_id,place_id\\n\")\n",
    "        rows = ['']*8607230\n",
    "        n=0\n",
    "        for num in range(8607230):\n",
    "            rows[n]='%d,%d %d %d\\n' % (preds[num,0],preds[num,1],preds[num,2],preds[num,3])\n",
    "            n=n+1\n",
    "        out.writelines(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Defining the parameters to be used in initializing the grid (x*y)\n",
    "fw = [0.61,0.32435, 0.56525, 0.2670, 22, 52, 0.51885]\n",
    "x_cuts = 20\n",
    "y_cuts = 40\n",
    "t_cuts = 4 ## Dividing the 24 hr time circle into 4 parts\n",
    "x_border_expansion = 0.05\n",
    "y_border_expansion = 0.017\n",
    "time_expansion = 2\n",
    "n_neighbors = 35\n",
    "val_start_day = 0\n",
    "th = 10 ## Threshold to seperate place_id. having less than 10 occurances\n",
    "features = ['x','y','minute_sine','minute_cosine','accuracy','day_sine','day_cosine','weekday_sine','weekday_cosine','year','place_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('the length of train before validation_split: ', 29118021)\n",
      "('the length of train after validation_split: ', 0)\n",
      "('length of train:', 0)\n",
      "Index([u'x', u'y', u'accuracy', u'time', u'place_id'], dtype='object')\n",
      "('the length of train: ', 0)\n",
      "('the length of train after apply weights: ', 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda2\\lib\\site-packages\\ipykernel\\__main__.py:38: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found array with 0 sample(s) (shape=(0, 14)) while a minimum of 1 is required.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-34-cf696e464aaf>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m preds = grid_process(train, test, x_cuts, y_cuts, t_cuts,\n\u001b[0;32m      3\u001b[0m                      \u001b[0mx_border_expansion\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_border_expansion\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtime_expansion\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m                      fw, th, n_neighbors)\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mval_start_day\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-31-c4b3097d70c6>\u001b[0m in \u001b[0;36mgrid_process\u001b[1;34m(train, test, x_cuts, y_cuts, t_cuts, x_border_expansion, y_border_expansion, time_epansion, fw, th, n_neighbors)\u001b[0m\n\u001b[0;32m     55\u001b[0m                 cell_pred = process_cell(df_cell_train.copy(), \n\u001b[0;32m     56\u001b[0m                                              \u001b[0mdf_cell_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 57\u001b[1;33m                                              fw, th, n_neighbors)\n\u001b[0m\u001b[0;32m     58\u001b[0m                 \u001b[0mpreds_list\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcell_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m         \u001b[0melapsed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mrow_start_time\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-33-f990026ed802>\u001b[0m in \u001b[0;36mprocess_cell\u001b[1;34m(train, test, fw, th, n_neighbors)\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[0mknn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mKNeighborsClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_neighbors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mn_neighbors\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mweights\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcalc_distance\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mleaf_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m15\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m     \u001b[0mknn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[0mpreds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mknn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda2\\lib\\site-packages\\sklearn\\neighbors\\base.pyc\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    776\u001b[0m         \"\"\"\n\u001b[0;32m    777\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mKDTree\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mBallTree\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 778\u001b[1;33m             \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"csr\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    779\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    780\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m2\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda2\\lib\\site-packages\\sklearn\\utils\\validation.pyc\u001b[0m in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    508\u001b[0m     X = check_array(X, accept_sparse, dtype, order, copy, force_all_finite,\n\u001b[0;32m    509\u001b[0m                     \u001b[0mensure_2d\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mallow_nd\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mensure_min_samples\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 510\u001b[1;33m                     ensure_min_features, warn_on_dtype, estimator)\n\u001b[0m\u001b[0;32m    511\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    512\u001b[0m         y = check_array(y, 'csr', force_all_finite=True, ensure_2d=False,\n",
      "\u001b[1;32mC:\\Anaconda2\\lib\\site-packages\\sklearn\\utils\\validation.pyc\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    405\u001b[0m                              \u001b[1;34m\" minimum of %d is required%s.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    406\u001b[0m                              % (n_samples, shape_repr, ensure_min_samples,\n\u001b[1;32m--> 407\u001b[1;33m                                 context))\n\u001b[0m\u001b[0;32m    408\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    409\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mensure_min_features\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Found array with 0 sample(s) (shape=(0, 14)) while a minimum of 1 is required."
     ]
    }
   ],
   "source": [
    "train,test,truth_val = prepare_data(0,fw)\n",
    "preds = grid_process(train, test, x_cuts, y_cuts, t_cuts,\n",
    "                     x_border_expansion, y_border_expansion, time_expansion, \n",
    "                     fw, th, n_neighbors)\n",
    "\n",
    "if val_start_day > 0:\n",
    "    preds = preds[preds[:, 0] > 0] # only use rows predicted\n",
    "    labels = val_label.loc[preds[:, 0]].values\n",
    "    score = mapkprecision(labels, preds[:, 1:])\n",
    "    print('Final score:', score)\n",
    "else:\n",
    "    generate_submission(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
