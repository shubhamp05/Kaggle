{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### _author_ = https://www.kaggle.com/shubhamp05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Function to merge item_info & item_pairs and drop irrelevant columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prepare_train_test(df_info, df_pairs):\n",
    "    merge_1 = pd.merge(left=df_pairs, right=df_info, left_on='itemID_1', right_on='itemID',how='inner')\n",
    "    merge_2 = pd.merge(left=merge_1, right=df_info,left_on='itemID_2', right_on='itemID',how='inner')\n",
    "    merge_2.drop(['itemID_x','images_array_x','itemID_y','images_array_y'],axis = 1,inplace=True)\n",
    "    return(merge_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Reading item_info & item_pairs (.csv) from input location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "item_info_train = pd.read_csv('ItemInfo_train.csv/ItemInfo_train.csv')\n",
    "item_pairs_train = pd.read_csv('ItemPairs_train.csv/ItemPairs_train.csv')\n",
    "item_info_test = pd.read_csv('ItemInfo_test.csv/ItemInfo_test.csv')\n",
    "item_pairs_test  = pd.read_csv('ItemPairs_test.csv/ItemPairs_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Preparing train & test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = prepare_train_test(item_info_train,item_pairs_train)\n",
    "test = prepare_train_test(item_info_test,item_pairs_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "itemID_1                  0\n",
       "itemID_2                  0\n",
       "isDuplicate               0\n",
       "generationMethod          0\n",
       "categoryID_x              0\n",
       "title_x                   1\n",
       "description_x            52\n",
       "attrsJSON_x          105866\n",
       "price_x              283894\n",
       "locationID_x              0\n",
       "metroID_x           1975769\n",
       "lat_x                     0\n",
       "lon_x                     0\n",
       "categoryID_y              0\n",
       "title_y                   0\n",
       "description_y            61\n",
       "attrsJSON_y          105866\n",
       "price_y              284231\n",
       "locationID_y              0\n",
       "metroID_y           1976172\n",
       "lat_y                     0\n",
       "lon_y                     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Removing missing value\n",
    "train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Missing values in train\n",
    "train.title_x.fillna(value=str(-1),inplace=True)\n",
    "train.description_x.fillna(value=str(-1),inplace=True)\n",
    "train.description_y.fillna(value=str(-1),inplace=True)\n",
    "train.attrsJSON_x.fillna(value=str(-1),inplace=True)\n",
    "train.attrsJSON_y.fillna(value=str(-1),inplace=True)\n",
    "train.price_x.fillna(value=-1,inplace=True)\n",
    "train.price_y.fillna(value=-1,inplace=True)\n",
    "train.metroID_x.fillna(value = -1,inplace=True)\n",
    "train.metroID_y.fillna(value = -1,inplace=True)\n",
    "\n",
    "## Missing values in test\n",
    "test.title_x.fillna(value=str(-1),inplace=True)\n",
    "test.description_x.fillna(value=str(-1),inplace=True)\n",
    "test.description_y.fillna(value=str(-1),inplace=True)\n",
    "test.attrsJSON_x.fillna(value=str(-1),inplace=True)\n",
    "test.attrsJSON_y.fillna(value=str(-1),inplace=True)\n",
    "test.price_x.fillna(value=-1,inplace=True)\n",
    "test.price_y.fillna(value=-1,inplace=True)\n",
    "test.metroID_x.fillna(value = -1,inplace=True)\n",
    "test.metroID_y.fillna(value = -1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Feature Extraction in train\n",
    "train['title_'] = np.equal(train.title_x,train.title_y).astype(int)\n",
    "train['category_'] = np.equal(train.categoryID_x,train.categoryID_y).astype(int)\n",
    "train['description_'] = np.equal(train.description_x,train.description_y).astype(int)\n",
    "train['json_'] = np.equal(train.attrsJSON_x,train.attrsJSON_y).astype(int)\n",
    "train['price'] = np.equal(train.price_x,train.price_y).astype(int)\n",
    "train['location_'] = np.equal(train.locationID_x,train.locationID_y).astype(int)\n",
    "train['metro_'] = np.equal(train.metroID_x,train.metroID_y).astype(int)\n",
    "train['lat_'] = np.equal(train.lat_x,train.lat_y).astype(int)\n",
    "train['lon_'] = np.equal(train.lon_x,train.lon_y).astype(int)\n",
    "train['len_title_diff'] = np.subtract(train.title_x.str.len().astype(int),train.title_y.str.len().astype(int))\n",
    "train['len_desc_diff'] = np.subtract(train.description_x.str.len().astype(int),train.description_y.str.len().astype(int))\n",
    "train['len_json_diff'] = np.subtract(train.attrsJSON_x.str.len().astype(int),train.attrsJSON_y.str.len().astype(int))\n",
    "train['price_diff'] = np.subtract(train.price_x,train.price_y)\n",
    "train['len_lat_diff'] = np.subtract(train.lat_x,train.lat_y)\n",
    "train['len_lon_diff'] = np.subtract(train.lon_x,train.lon_y)\n",
    "\n",
    "## Feature extraction in test\n",
    "test['title_'] = np.equal(test.title_x,test.title_y).astype(int)\n",
    "test['category_'] = np.equal(test.categoryID_x,test.categoryID_y).astype(int)\n",
    "test['description_'] = np.equal(test.description_x,test.description_y).astype(int)\n",
    "test['json_'] = np.equal(test.attrsJSON_x,test.attrsJSON_y).astype(int)\n",
    "test['price'] = np.equal(test.price_x,test.price_y).astype(int)\n",
    "test['location_'] = np.equal(test.locationID_x,test.locationID_y).astype(int)\n",
    "test['metro_'] = np.equal(test.metroID_x,test.metroID_y).astype(int)\n",
    "test['lat_'] = np.equal(test.lat_x,test.lat_y).astype(int)\n",
    "test['lon_'] = np.equal(test.lon_x,test.lon_y).astype(int)\n",
    "test['len_title_diff'] = np.subtract(test.title_x.str.len().astype(int),test.title_y.str.len().astype(int))\n",
    "test['len_desc_diff'] = np.subtract(test.description_x.str.len().astype(int),test.description_y.str.len().astype(int))\n",
    "test['len_json_diff'] = np.subtract(test.attrsJSON_x.str.len().astype(int),test.attrsJSON_y.str.len().astype(int))\n",
    "test['price_diff'] = np.subtract(test.price_x,test.price_y)\n",
    "test['len_lat_diff'] = np.subtract(test.lat_x,test.lat_y)\n",
    "test['len_lon_diff'] = np.subtract(test.lon_x,test.lon_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "features = ['title_','category_','description_','json_','price','location_','metro_','lat_','lon_','len_title_diff','len_desc_diff','len_json_diff','price_diff','len_lat_diff','len_lon_diff']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Applying Random forest classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = train.isDuplicate.values\n",
    "train.drop('isDuplicate',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rfc = RandomForestClassifier(n_estimators=1000,max_features=\"log2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#rfc.fit(train[features],y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gbm = GradientBoostingClassifier(n_estimators=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
       "              max_depth=3, max_features=None, max_leaf_nodes=None,\n",
       "              min_samples_leaf=1, min_samples_split=2,\n",
       "              min_weight_fraction_leaf=0.0, n_estimators=1000,\n",
       "              presort='auto', random_state=None, subsample=1.0, verbose=0,\n",
       "              warm_start=False)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbm.fit(train[features],y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "preds = gbm.predict_proba(test[features])[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
